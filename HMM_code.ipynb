{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IdeaaEtiquetadoMorfologico_Anexo2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjfJq-OHiWs4"
      },
      "source": [
        "# Importación de librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFoxUYXqiVr0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biPvzQYpZsRS"
      },
      "source": [
        "# Definición de clases auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URI917cmZ2HM"
      },
      "source": [
        "En esta sección se definirán dos clases que servirán para agrupar información a la entrada y a la salida de la clase *HMMBigram*, que será donde se calculen las tablas probabilísticas de transición y obvservación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-6JtfxM7-x7"
      },
      "source": [
        "class Word:\n",
        "    '''\n",
        "    It stores the most important properties of each word from the corpus\n",
        "    '''\n",
        "\n",
        "    def __init__(self, token: str, tag: str, lemma: str):\n",
        "        '''\n",
        "        Class constructor.\n",
        "        Parameters:\n",
        "        -token: Word token\n",
        "        -tag: Word tag\n",
        "        '''\n",
        "        self._token = token\n",
        "        self._tag = tag\n",
        "        self._lemma = lemma\n",
        "\n",
        "    def Token(self):\n",
        "        '''\n",
        "        Returns the token of the word\n",
        "        '''\n",
        "        return self._token\n",
        "\n",
        "    def Tag(self):\n",
        "        '''\n",
        "        Returns the tag of the word\n",
        "        '''\n",
        "        return self._tag\n",
        "\n",
        "    def Lemma(self):\n",
        "        '''\n",
        "        Returns the lemma of the word\n",
        "        '''\n",
        "        return self._lemma\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoRtcqN8hg4Q"
      },
      "source": [
        "class HMM_Probabilities:\n",
        "    '''\n",
        "    It stores the transition and emission probabilities of each document of the corpus\n",
        "    '''\n",
        "\n",
        "    def __init__(self, _prob_trans: pd.DataFrame(), _prob_obs: pd.DataFrame()):\n",
        "        '''\n",
        "        Class constructor.\n",
        "        Parameters:\n",
        "        -_prob_trans: The probability table of transition\n",
        "        -_prob_obs: The probability table of emission\n",
        "        '''\n",
        "        self._prob_trans = _prob_trans\n",
        "        self._prob_obs =  _prob_obs\n",
        "\n",
        "    def PTrans(self):\n",
        "        '''\n",
        "        Returns the probability table of transition stored\n",
        "        '''\n",
        "        return self._prob_trans\n",
        "\n",
        "    def PObs(self):\n",
        "        '''\n",
        "        Returs the probability table of emission stored\n",
        "        '''\n",
        "        return self._prob_obs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKYscj3IbnIY"
      },
      "source": [
        "Se declara también la función *non_zero_green*, que se utilizará como medio para mostrar con mayor claridad algunos valores de las tablas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AraNQ7A7bQxy"
      },
      "source": [
        "def non_zero_green(val):\n",
        "    '''\n",
        "    Function to highlight probabilities other than 0 in green\n",
        "    '''\n",
        "    return 'background-color: Aquamarine' if val > 0 else ''  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2-O-PrqZq59"
      },
      "source": [
        "# Definición de la clase HMMBigram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Eg5WW9e7-x8"
      },
      "source": [
        "Esta clase permitirá hacer el cálculo de las tablas de probabilidades de transición y de emisión a partir de la información agrupada del corpus (por la clase *Word*). Como no se calcularán las tablas finales de forma instantánea, sino que se calcularán por separado para cada archivo de wikicorpus descargado, la clase *HMM_Probabilities* almacenará cada set de probabilidades calculado en cada caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt64W0sq7-x-"
      },
      "source": [
        "class HMMBigram:\n",
        "    '''    \n",
        "    Class to obtain the probability matrices HMM Bigrama from a corpus\n",
        "    '''\n",
        "\n",
        "    def __init__(self, corpus: [[Word]], LemmaDictionary: dict(), RemovedLemmaDict: dict()):\n",
        "        '''\n",
        "        Class constructor\n",
        "        Parameters:\n",
        "        -corpus: The corpus to proc\n",
        "        -LemmaDictionary: The dictionary of lemmas to create\n",
        "        -RemovedLemmaDict: The dictionary of deleted tokens and its lemmas\n",
        "        '''\n",
        "        self._corpus = corpus\n",
        "        self._states = dict()\n",
        "        self._tokens = dict()\n",
        "        self._reducedtokens = dict()\n",
        "        self._lemmas_dict = LemmaDictionary\n",
        "\n",
        "        self._removedDict = RemovedLemmaDict\n",
        "        self._q0 = 'q0'\n",
        "        self._qF = 'qF'\n",
        "        self.state_dictionary = {\"A\":\"Adjective\", \"D\":\"Determiner\", \"N\":\"Noun\", \"V\":\"Verb\", \"P\":\"Pronoun\", \"R\":\"Adverb\", \"C\":\"Conjunction\", \"S\":\"Adposition\", \"W\":\"Date\", \"Z\":\"Number\", \"I\":\"Interjection\", \"F\":\"Punctuation\"}\n",
        "\n",
        "        self._prob_trans = pd.DataFrame()\n",
        "        self._prob_obs = pd.DataFrame()\n",
        "\n",
        "\n",
        "    def LemmaDictionaries(self):\n",
        "        '''    \n",
        "        Returns the dictionary of lemmas created\n",
        "        '''\n",
        "        return self._lemmas_dict\n",
        "\n",
        "    def RemovedLemmaDict(self):\n",
        "        '''    \n",
        "        Returns the dictionary of deleted lemmas created\n",
        "        '''\n",
        "        return self._removedDict\n",
        "\n",
        "\n",
        "    def CorpusProcessing(self):\n",
        "        '''\n",
        "        Counts the number of occurrences of states and tokens and identifies the \"tokenseliminados\"\n",
        "        '''\n",
        "        for sentence in self._corpus:\n",
        "            \n",
        "            for word in sentence:\n",
        "\n",
        "                #Getting the frequency of appearance for each word (without filtering)\n",
        "\n",
        "                if self.state_dictionary[word.Tag()[0]] in self._states.keys():\n",
        "                    self._states[self.state_dictionary[word.Tag()[0]]]+=1\n",
        "\n",
        "                else:\n",
        "                    self._states[self.state_dictionary[word.Tag()[0]]]=1\n",
        "\n",
        "                if word.Token().lower() in self._tokens.keys():\n",
        "                    self._tokens[word.Token().lower()]+=1\n",
        "\n",
        "                else:\n",
        "                    self._tokens[word.Token().lower()]=1\n",
        "\n",
        "                #Getting the frequency of appearance for each word (with filtering)\n",
        "                if word.Tag()[0] != \"W\" and word.Tag()[0] != \"Z\" and word.Tag()[:2] != \"NP\":\n",
        "                    CompoundWord = word.Token().count('_')\n",
        "                    WrongWord = word.Token().count('.')\n",
        "                    if CompoundWord == 0 and WrongWord== 0:\n",
        "\n",
        "                          #Creating the dictionary of lemmas\n",
        "                          if not word.Token().lower() in  self._lemmas_dict.keys():\n",
        "                              self._lemmas_dict[word.Token().lower()] = dict()\n",
        "                              self._lemmas_dict[word.Token().lower()][self.state_dictionary[word.Tag()[0]]] = word.Lemma().lower() \n",
        "                          else:\n",
        "                              self._lemmas_dict[word.Token().lower()][self.state_dictionary[word.Tag()[0]]] = word.Lemma().lower() \n",
        "\n",
        "     \n",
        "                          #If the word does not need to be filtered\n",
        "                          if word.Token().lower() in self._reducedtokens.keys():\n",
        "                              self._reducedtokens[word.Token().lower()]+=1\n",
        "\n",
        "                          else:\n",
        "                              self._reducedtokens[word.Token().lower()]=1\n",
        "                    else:\n",
        "                        #If the word needs to be filtered\n",
        "                        if \"tokenseliminados\" in self._reducedtokens.keys():\n",
        "                              self._reducedtokens[\"tokenseliminados\"]+=1\n",
        "\n",
        "                        else:\n",
        "                            self._reducedtokens[\"tokenseliminados\"]=1\n",
        "                else:\n",
        "                    #Creating the dictionary of removed lemmas\n",
        "                    if not word.Token().lower() in  self._removedDict.keys():\n",
        "                          self._removedDict[word.Token().lower()] = dict()\n",
        "                          self._removedDict[word.Token().lower()][self.state_dictionary[word.Tag()[0]]] = word.Lemma().lower()  \n",
        "                    else:\n",
        "                        self._removedDict[word.Token().lower()][self.state_dictionary[word.Tag()[0]]] = word.Lemma().lower() \n",
        "\n",
        "\n",
        "    def States(self, include_initial: bool = False, include_last: bool = False):\n",
        "        '''\n",
        "        Returns the states of the corpus.\n",
        "        Parameters:\n",
        "        -include_initial: includes q0\n",
        "        -include_last : includes qf\n",
        "        '''\n",
        "\n",
        "        if len(self._states) == 0:\n",
        "            self.CorpusProcessing()\n",
        "\n",
        "        states_copy = dict()\n",
        "        #Adding q0\n",
        "        if include_initial:\n",
        "            states_copy[self._q0] = len(self._corpus)\n",
        "\n",
        "        states_copy.update(self._states)\n",
        "        #Adding qf\n",
        "        if include_last:\n",
        "            states_copy[self._qF] = len(self._corpus)\n",
        "\n",
        "        return states_copy\n",
        "\n",
        "    def Tokens(self):\n",
        "        '''\n",
        "        Returns the tokens of the corpus\n",
        "        '''\n",
        "\n",
        "        if len(self._tokens) == 0:\n",
        "            self.CorpusProcessing()\n",
        "\n",
        "        return self._tokens.copy()\n",
        "\n",
        "    def ReducedTokens(self):\n",
        "        '''\n",
        "        Returns the filtered list of tokens\n",
        "        '''\n",
        "\n",
        "        if len(self._reducedtokens) == 0:\n",
        "            self.CorpusProcessing()\n",
        "\n",
        "        return self._reducedtokens.copy()\n",
        "\n",
        "    \n",
        "    def TransitionProbabilities(self):  \n",
        "        '''\n",
        "        Calculates the probabilities of transition\n",
        "        '''\n",
        "\n",
        "        if len(self._prob_trans) != 0:\n",
        "            return self._prob_trans.copy()\n",
        "\n",
        "        q0 = self._q0\n",
        "        qF = self._qF\n",
        " \n",
        "        transition_count = dict()\n",
        "        aux_dict = dict()\n",
        "        \n",
        "        #Creating an empty dictionary with the correct keys \n",
        "        for state in self.States(include_initial=True, include_last=True).keys():\n",
        "            for state2 in self.States(include_initial=True,include_last=True).keys():\n",
        "                aux_dict[state2] = 0     \n",
        "            transition_count[state]= aux_dict.copy()\n",
        "            aux_dict.clear()\n",
        "            \n",
        "        #Getting the transition count between states and filling the previous empty dictionary\n",
        "        previous_word = self._q0\n",
        "        for sentence in self._corpus:\n",
        "            cnt = 0\n",
        "            for word in sentence:\n",
        "                if cnt == 0:\n",
        "                    transition_count[self._q0][self.state_dictionary[word.Tag()[0]]] += 1\n",
        "                    previous_word = self.state_dictionary[word.Tag()[0]]\n",
        "                    cnt=1\n",
        "                    \n",
        "                else:                    \n",
        "                    transition_count[previous_word][self.state_dictionary[word.Tag()[0]]] += 1\n",
        "                    previous_word = self.state_dictionary[word.Tag()[0]]\n",
        "\n",
        "            \n",
        "            transition_count[self.state_dictionary[word.Tag()[0]]][self._qF] += 1\n",
        "\n",
        "        #Getting additional information to adjust the probability table of transition\n",
        "        initial_tags_states = list(\n",
        "            self.States(include_initial=True).keys())\n",
        "        final_tags_states = list(self.States(include_last=True).keys())\n",
        "        total_states = self.States(\n",
        "            include_initial=True, include_last=True)\n",
        "\n",
        "        prob_trans_dict = dict()\n",
        "\n",
        "        #Creating an empty dictionary\n",
        "        for state in self.States(include_initial=True, include_last=True).keys():\n",
        "            for state2 in self.States(include_initial=True,include_last=True).keys():\n",
        "                aux_dict[state2] = 0     \n",
        "            prob_trans_dict[state]= aux_dict.copy()\n",
        "            aux_dict.clear()\n",
        "        \n",
        "        #Filling the dictionary with the probability table of transition\n",
        "        for state in self.States(include_initial=True, include_last=True).keys():\n",
        "            for state2 in self.States(include_initial=True,include_last=True).keys():\n",
        "                prob_trans_dict[state2][state] = transition_count[state][state2] / total_states[state]\n",
        "                \n",
        "        #Converting the information\n",
        "        self._prob_trans = pd.DataFrame().from_dict(prob_trans_dict.copy()) \n",
        "\n",
        "\n",
        "        return self._prob_trans.copy()\n",
        "          \n",
        "\n",
        "\n",
        "    def EmissionProbabilities(self):\n",
        "        '''\n",
        "        Calculates the probabilities of emission\n",
        "        '''\n",
        "\n",
        "        if len(self._prob_obs) != 0:\n",
        "            return self._prob_obs.copy()\n",
        "\n",
        "\n",
        "        states = self.States()\n",
        "        observation_count = dict()\n",
        "        aux_dict = dict()\n",
        "\n",
        "        #Creating an empty dictionary with the correct keys\n",
        "        for state in self.States().keys():\n",
        "            for word in self.ReducedTokens().keys():\n",
        "                aux_dict[word.lower()] = 0     \n",
        "            observation_count[state]= aux_dict.copy()\n",
        "            aux_dict.clear()\n",
        "\n",
        "        #Getting the emission count between states and filling the previous empty dictionary\n",
        "        for sentence in self._corpus:\n",
        "            for word in sentence:\n",
        "              try:\n",
        "                observation_count[self.state_dictionary[word.Tag()[0]]][word.Token().lower()] += 1\n",
        "              except:\n",
        "                observation_count[self.state_dictionary[word.Tag()[0]]][\"tokenseliminados\"] += 1               \n",
        "\n",
        "                             \n",
        "        tokens = self.ReducedTokens()\n",
        "        prob_obs = {Ti: {Wi: 0 for Wi in tokens} for Ti in states}\n",
        "\n",
        "        prob_obs_dict = dict()\n",
        "        total_states = self.States()\n",
        "\n",
        "        #Creating an empty dictionary \n",
        "        for word in self.ReducedTokens().keys():\n",
        "            for state in self.States().keys():                        \n",
        "                aux_dict[state] = 0     \n",
        "            prob_obs_dict[word.lower()]= aux_dict.copy()\n",
        "            aux_dict.clear()\n",
        "\n",
        "        #Filling the dictionary with the probability table of emission\n",
        "        for state in self.States().keys():\n",
        "            for word in self.ReducedTokens().keys():            \n",
        "                prob_obs_dict[word.lower()][state] = observation_count[state][word.lower()] / total_states[state]           \n",
        "              \n",
        "        #Converting the information        \n",
        "        self._prob_obs = pd.DataFrame().from_dict(prob_obs_dict.copy()) \n",
        "\n",
        "        return self._prob_obs\n",
        "\n",
        "    def __Corpus(self):\n",
        "        '''\n",
        "        Returns the corpus that has been processed\n",
        "        '''\n",
        "        return self._corpus.copy()\n",
        "\n",
        "    def __InitialState(self):\n",
        "        '''\n",
        "        Returns the initial state\n",
        "        '''\n",
        "        return self._q0\n",
        "\n",
        "    def __FinalState(self):\n",
        "        '''\n",
        "        Returns the final state\n",
        "        '''\n",
        "        return self._qF\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsoDiPsqwIPw"
      },
      "source": [
        "# Obtención de las tablas de probabilidad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUIAtxB97-x_"
      },
      "source": [
        "En esta sección, se iterará por el número de ficheros disponibles de Wikicorpus, se calcularán sus probabilidades y se almacenarán en la lista denominada HMM. A partir de esta lista, se obtendrán las tablas finales de emisión y transición en función de la aparición de las palabras en cada fichero (mediante una media relativa al número de éstas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-xYV7-OjFvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fdfa57-7a89-4c91-dd6c-6602497414cb"
      },
      "source": [
        "HMM = list()\n",
        "DictLemmas = dict()\n",
        "RemovedLemmaDict = dict()\n",
        "#Uploading the files\n",
        "for document in os.listdir(\"Wikicorpus\"):\n",
        "    if document != \".ipynb_checkpoints\":\n",
        "      wikicorpus_file = open(\"Wikicorpus/\"+document, \"r\", encoding = \"ISO-8859-1\",)\n",
        "      actual_sentence = list()\n",
        "      corpus = list()\n",
        "      print(document)\n",
        "\n",
        "      #Reading each line of the file\n",
        "      for line in wikicorpus_file.readlines():\n",
        "          line = line.split()\n",
        "          if len(line) == 0:\n",
        "              if len(actual_sentence) > 0:\n",
        "                  corpus.append(actual_sentence)\n",
        "\n",
        "              actual_sentence = list()\n",
        "              continue\n",
        "\n",
        "          elif line[0] == '<doc':\n",
        "              #Start of document. Nothing is done\n",
        "              continue\n",
        "\n",
        "          elif line[0] == '</doc>':\n",
        "              #End of document. Nothing is done\n",
        "              continue\n",
        "          try:\n",
        "            actual_sentence.append(Word(token=line[0], tag=line[2], lemma = line[1]))\n",
        "            if line[2] == 'mito' or len(line) > 4 :\n",
        "              print(line)\n",
        "          except:\n",
        "            print(line)\n",
        "    \n",
        "\n",
        "      wikicorpus_file.close()\n",
        "      #Calculating the HMM of the file\n",
        "      hmmbigram = HMMBigram(corpus, DictLemmas, RemovedLemmaDict)\n",
        "      hmmbigram.CorpusProcessing()\n",
        "      #Getting the dictionary of lemmas and the dictionary of removed lemmas\n",
        "      DictLemmas= hmmbigram.LemmaDictionaries()\n",
        "      RemovedLemmaDict = hmmbigram.RemovedLemmaDict()\n",
        "      #Getting the probability tables\n",
        "      prob_transition = hmmbigram.TransitionProbabilities()\n",
        "      prob_transition.to_excel(\"Desktop/docs/\"+document+'resultados_trans.xlsx', sheet_name='prob_trans')\n",
        "      prob_emission = hmmbigram.EmissionProbabilities().T\n",
        "      prob_emission.to_excel(\"Desktop/docs/\"+document+'resultados_emision.xlsx', sheet_name='prob_emission')\n",
        "      #Storing the probability tables in the HMM list\n",
        "      HMM.append(HMM_Probabilities(prob_transition, prob_emission.T))\n",
        "\n",
        "      del hmmbigram\n",
        "      del prob_transition\n",
        "      del prob_emission"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SE_110k_115k.txt\n",
            "SE_180k_185k.txt\n",
            "SE_185k_190k.txt\n",
            "SE_200k_205k.txt\n",
            "SE_225k_230k.txt\n",
            "SE_230k_235k.txt\n",
            "SE_25k_30k.txt\n",
            "SE_260k_265k.txt\n",
            "SE_285k_290k.txt\n",
            "SE_305k_310k.txt\n",
            "SE_310k_315k.txt\n",
            "SE_315k_320k.txt\n",
            "SE_320k_325k.txt\n",
            "SE_330k_335k.txt\n",
            "SE_335k_340k.txt\n",
            "SE_340k_345k.txt\n",
            "SE_345k_350k.txt\n",
            "SE_355k_360k.txt\n",
            "SE_360k_365k.txt\n",
            "SE_365k_370k.txt\n",
            "SE_370k_375k.txt\n",
            "SE_375k_380k.txt\n",
            "SE_380k_385k.txt\n",
            "SE_385k_390k.txt\n",
            "SE_390k_395k.txt\n",
            "SE_405k_410k.txt\n",
            "SE_425k_430k.txt\n",
            "SE_430k_435k.txt\n",
            "SE_435k_440k.txt\n",
            "SE_440_445k.txt\n",
            "SE_470k_475k.txt\n",
            "SE_90k_95k.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGI6Cm_8x-Gn"
      },
      "source": [
        "A continuación, se muestra un ejemplo de la lista HMM, mostrando las tablas de transición y emisión guardadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "9yvoDaxqsgCK",
        "outputId": "78b93635-757c-44a7-eb2f-37208f7f9f69"
      },
      "source": [
        "HMM[0].PTrans().style.applymap(non_zero_green)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0xfc0c06eb0>"
            ],
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col13,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col12,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col1,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col2,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col3,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col4,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col5,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col6,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col7,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col8,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col9,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col10,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col11,#T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col12{\n",
              "            background-color:  Aquamarine;\n",
              "        }</style><table id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >q0</th>        <th class=\"col_heading level0 col1\" >Determiner</th>        <th class=\"col_heading level0 col2\" >Noun</th>        <th class=\"col_heading level0 col3\" >Verb</th>        <th class=\"col_heading level0 col4\" >Adposition</th>        <th class=\"col_heading level0 col5\" >Adjective</th>        <th class=\"col_heading level0 col6\" >Punctuation</th>        <th class=\"col_heading level0 col7\" >Conjunction</th>        <th class=\"col_heading level0 col8\" >Pronoun</th>        <th class=\"col_heading level0 col9\" >Adverb</th>        <th class=\"col_heading level0 col10\" >Number</th>        <th class=\"col_heading level0 col11\" >Date</th>        <th class=\"col_heading level0 col12\" >Interjection</th>        <th class=\"col_heading level0 col13\" >qF</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row0\" class=\"row_heading level0 row0\" >q0</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col1\" class=\"data row0 col1\" >0.249160</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col2\" class=\"data row0 col2\" >0.318593</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col3\" class=\"data row0 col3\" >0.109062</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col4\" class=\"data row0 col4\" >0.171052</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col5\" class=\"data row0 col5\" >0.004547</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col6\" class=\"data row0 col6\" >0.010995</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col7\" class=\"data row0 col7\" >0.028374</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col8\" class=\"data row0 col8\" >0.035704</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col9\" class=\"data row0 col9\" >0.055023</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col10\" class=\"data row0 col10\" >0.015718</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col11\" class=\"data row0 col11\" >0.001559</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col12\" class=\"data row0 col12\" >0.000213</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row0_col13\" class=\"data row0 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row1\" class=\"row_heading level0 row1\" >Determiner</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col1\" class=\"data row1 col1\" >0.011758</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col2\" class=\"data row1 col2\" >0.808015</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col3\" class=\"data row1 col3\" >0.013182</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col4\" class=\"data row1 col4\" >0.009249</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col5\" class=\"data row1 col5\" >0.082384</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col6\" class=\"data row1 col6\" >0.004906</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col7\" class=\"data row1 col7\" >0.001100</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col8\" class=\"data row1 col8\" >0.025491</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col9\" class=\"data row1 col9\" >0.006354</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col10\" class=\"data row1 col10\" >0.017866</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col11\" class=\"data row1 col11\" >0.019659</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col12\" class=\"data row1 col12\" >0.000036</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row1_col13\" class=\"data row1 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row2\" class=\"row_heading level0 row2\" >Noun</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col1\" class=\"data row2 col1\" >0.010561</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col2\" class=\"data row2 col2\" >0.048491</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col3\" class=\"data row2 col3\" >0.088396</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col4\" class=\"data row2 col4\" >0.245157</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col5\" class=\"data row2 col5\" >0.111023</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col6\" class=\"data row2 col6\" >0.363798</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col7\" class=\"data row2 col7\" >0.067022</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col8\" class=\"data row2 col8\" >0.033353</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col9\" class=\"data row2 col9\" >0.018431</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col10\" class=\"data row2 col10\" >0.012697</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col11\" class=\"data row2 col11\" >0.000488</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col12\" class=\"data row2 col12\" >0.000582</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row2_col13\" class=\"data row2 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row3\" class=\"row_heading level0 row3\" >Verb</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col1\" class=\"data row3 col1\" >0.227699</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col2\" class=\"data row3 col2\" >0.086812</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col3\" class=\"data row3 col3\" >0.140377</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col4\" class=\"data row3 col4\" >0.295037</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col5\" class=\"data row3 col5\" >0.030314</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col6\" class=\"data row3 col6\" >0.064043</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col7\" class=\"data row3 col7\" >0.052566</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col8\" class=\"data row3 col8\" >0.040454</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col9\" class=\"data row3 col9\" >0.049960</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col10\" class=\"data row3 col10\" >0.012497</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col11\" class=\"data row3 col11\" >0.000121</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col12\" class=\"data row3 col12\" >0.000121</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row3_col13\" class=\"data row3 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row4\" class=\"row_heading level0 row4\" >Adposition</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col1\" class=\"data row4 col1\" >0.512150</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col2\" class=\"data row4 col2\" >0.313212</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col3\" class=\"data row4 col3\" >0.050803</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col4\" class=\"data row4 col4\" >0.002159</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col5\" class=\"data row4 col5\" >0.019188</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col6\" class=\"data row4 col6\" >0.005896</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col7\" class=\"data row4 col7\" >0.006043</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col8\" class=\"data row4 col8\" >0.020845</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col9\" class=\"data row4 col9\" >0.007539</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col10\" class=\"data row4 col10\" >0.056865</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col11\" class=\"data row4 col11\" >0.005251</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col12\" class=\"data row4 col12\" >0.000048</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row4_col13\" class=\"data row4 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row5\" class=\"row_heading level0 row5\" >Adjective</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col1\" class=\"data row5 col1\" >0.011215</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col2\" class=\"data row5 col2\" >0.257580</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col3\" class=\"data row5 col3\" >0.065085</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col4\" class=\"data row5 col4\" >0.221025</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col5\" class=\"data row5 col5\" >0.021900</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col6\" class=\"data row5 col6\" >0.294795</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col7\" class=\"data row5 col7\" >0.084907</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col8\" class=\"data row5 col8\" >0.029432</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col9\" class=\"data row5 col9\" >0.010011</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col10\" class=\"data row5 col10\" >0.003562</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col11\" class=\"data row5 col11\" >0.000459</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col12\" class=\"data row5 col12\" >0.000029</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row5_col13\" class=\"data row5 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row6\" class=\"row_heading level0 row6\" >Punctuation</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col1\" class=\"data row6 col1\" >0.057034</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col2\" class=\"data row6 col2\" >0.251712</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col3\" class=\"data row6 col3\" >0.069913</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col4\" class=\"data row6 col4\" >0.071242</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col5\" class=\"data row6 col5\" >0.012565</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col6\" class=\"data row6 col6\" >0.102883</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col7\" class=\"data row6 col7\" >0.054243</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col8\" class=\"data row6 col8\" >0.031118</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col9\" class=\"data row6 col9\" >0.019076</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col10\" class=\"data row6 col10\" >0.055198</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col11\" class=\"data row6 col11\" >0.003539</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col12\" class=\"data row6 col12\" >0.000751</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row6_col13\" class=\"data row6 col13\" >0.270725</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row7\" class=\"row_heading level0 row7\" >Conjunction</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col1\" class=\"data row7 col1\" >0.216529</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col2\" class=\"data row7 col2\" >0.291573</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col3\" class=\"data row7 col3\" >0.151233</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col4\" class=\"data row7 col4\" >0.105575</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col5\" class=\"data row7 col5\" >0.052964</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col6\" class=\"data row7 col6\" >0.025285</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col7\" class=\"data row7 col7\" >0.011827</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col8\" class=\"data row7 col8\" >0.062673</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col9\" class=\"data row7 col9\" >0.057161</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col10\" class=\"data row7 col10\" >0.023540</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col11\" class=\"data row7 col11\" >0.001536</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col12\" class=\"data row7 col12\" >0.000105</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row7_col13\" class=\"data row7 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row8\" class=\"row_heading level0 row8\" >Pronoun</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col1\" class=\"data row8 col1\" >0.036758</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col2\" class=\"data row8 col2\" >0.025993</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col3\" class=\"data row8 col3\" >0.627845</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col4\" class=\"data row8 col4\" >0.090202</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col5\" class=\"data row8 col5\" >0.009408</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col6\" class=\"data row8 col6\" >0.047187</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col7\" class=\"data row8 col7\" >0.013894</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col8\" class=\"data row8 col8\" >0.098533</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col9\" class=\"data row8 col9\" >0.048465</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col10\" class=\"data row8 col10\" >0.001615</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col11\" class=\"data row8 col11\" >0.000045</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col12\" class=\"data row8 col12\" >0.000056</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row8_col13\" class=\"data row8 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row9\" class=\"row_heading level0 row9\" >Adverb</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col1\" class=\"data row9 col1\" >0.073572</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col2\" class=\"data row9 col2\" >0.053709</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col3\" class=\"data row9 col3\" >0.277721</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col4\" class=\"data row9 col4\" >0.149489</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col5\" class=\"data row9 col5\" >0.144527</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col6\" class=\"data row9 col6\" >0.137833</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col7\" class=\"data row9 col7\" >0.032538</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col8\" class=\"data row9 col8\" >0.064719</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col9\" class=\"data row9 col9\" >0.054338</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col10\" class=\"data row9 col10\" >0.011197</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col11\" class=\"data row9 col11\" >0.000051</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col12\" class=\"data row9 col12\" >0.000306</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row9_col13\" class=\"data row9 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row10\" class=\"row_heading level0 row10\" >Number</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col1\" class=\"data row10 col1\" >0.010498</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col2\" class=\"data row10 col2\" >0.255521</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col3\" class=\"data row10 col3\" >0.038235</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col4\" class=\"data row10 col4\" >0.093187</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col5\" class=\"data row10 col5\" >0.010946</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col6\" class=\"data row10 col6\" >0.498352</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col7\" class=\"data row10 col7\" >0.045974</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col8\" class=\"data row10 col8\" >0.013675</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col9\" class=\"data row10 col9\" >0.008336</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col10\" class=\"data row10 col10\" >0.024620</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col11\" class=\"data row10 col11\" >0.000611</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col12\" class=\"data row10 col12\" >0.000045</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row10_col13\" class=\"data row10 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row11\" class=\"row_heading level0 row11\" >Date</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col1\" class=\"data row11 col1\" >0.033480</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col2\" class=\"data row11 col2\" >0.047508</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col3\" class=\"data row11 col3\" >0.078088</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col4\" class=\"data row11 col4\" >0.147760</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col5\" class=\"data row11 col5\" >0.003647</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col6\" class=\"data row11 col6\" >0.557748</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col7\" class=\"data row11 col7\" >0.058449</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col8\" class=\"data row11 col8\" >0.040120</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col9\" class=\"data row11 col9\" >0.004676</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col10\" class=\"data row11 col10\" >0.022258</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col11\" class=\"data row11 col11\" >0.006266</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col12\" class=\"data row11 col12\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row11_col13\" class=\"data row11 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row12\" class=\"row_heading level0 row12\" >Interjection</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col1\" class=\"data row12 col1\" >0.007380</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col2\" class=\"data row12 col2\" >0.474785</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col3\" class=\"data row12 col3\" >0.035670</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col4\" class=\"data row12 col4\" >0.019680</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col5\" class=\"data row12 col5\" >0.004920</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col6\" class=\"data row12 col6\" >0.382534</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col7\" class=\"data row12 col7\" >0.012300</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col8\" class=\"data row12 col8\" >0.025830</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col9\" class=\"data row12 col9\" >0.017220</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col10\" class=\"data row12 col10\" >0.011070</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col11\" class=\"data row12 col11\" >0.001230</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col12\" class=\"data row12 col12\" >0.007380</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row12_col13\" class=\"data row12 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480level0_row13\" class=\"row_heading level0 row13\" >qF</th>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col1\" class=\"data row13 col1\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col2\" class=\"data row13 col2\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col3\" class=\"data row13 col3\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col4\" class=\"data row13 col4\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col5\" class=\"data row13 col5\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col6\" class=\"data row13 col6\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col7\" class=\"data row13 col7\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col8\" class=\"data row13 col8\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col9\" class=\"data row13 col9\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col10\" class=\"data row13 col10\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col11\" class=\"data row13 col11\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col12\" class=\"data row13 col12\" >0.000000</td>\n",
              "                        <td id=\"T_9d0e79fa_1315_11ec_88c1_303a6434a480row13_col13\" class=\"data row13 col13\" >0.000000</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "wrsXdTbctxvA",
        "outputId": "0d6217ef-7aa3-4d86-b944-7f93eb642417"
      },
      "source": [
        "HMM[0].PObs()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    la        es       una  institución        de  educación  \\\n",
              "Determiner    0.250913  0.000000  0.054342     0.000000  0.000000   0.000000   \n",
              "Noun          0.001173  0.000079  0.000000     0.000247  0.000099   0.000426   \n",
              "Verb          0.000000  0.059271  0.000000     0.000000  0.000000   0.000000   \n",
              "Adposition    0.000000  0.000000  0.000000     0.000000  0.426120   0.000000   \n",
              "Adjective     0.000000  0.000000  0.000000     0.000000  0.000000   0.000000   \n",
              "Punctuation   0.000000  0.000000  0.000000     0.000000  0.000000   0.000000   \n",
              "Conjunction   0.000000  0.000000  0.000000     0.000000  0.000000   0.000000   \n",
              "Pronoun       0.015037  0.000000  0.001110     0.000000  0.000000   0.000000   \n",
              "Adverb        0.000000  0.000000  0.000000     0.000000  0.000000   0.000000   \n",
              "Number        0.000000  0.000000  0.000567     0.000000  0.000000   0.000000   \n",
              "Date          0.000000  0.000000  0.000000     0.000000  0.000000   0.000000   \n",
              "Interjection  0.000000  0.000000  0.000000     0.000000  0.000000   0.000000   \n",
              "\n",
              "              superior  inspiración  cristiana         ,  ...  espiritu  \\\n",
              "Determiner    0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "Noun          0.000006     0.000065   0.000002  0.000000  ...  0.000002   \n",
              "Verb          0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "Adposition    0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "Adjective     0.002114     0.000000   0.000537  0.000000  ...  0.000000   \n",
              "Punctuation   0.000000     0.000000   0.000000  0.343961  ...  0.000000   \n",
              "Conjunction   0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "Pronoun       0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "Adverb        0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "Number        0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "Date          0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "Interjection  0.000000     0.000000   0.000000  0.000000  ...  0.000000   \n",
              "\n",
              "              desalineación  neandertales  cro-magnon  cromañón  prognatismo  \\\n",
              "Determiner         0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Noun               0.000002      0.000002    0.000002  0.000002     0.000005   \n",
              "Verb               0.000000      0.000000    0.000004  0.000000     0.000000   \n",
              "Adposition         0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Adjective          0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Punctuation        0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Conjunction        0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Pronoun            0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Adverb             0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Number             0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Date               0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "Interjection       0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "\n",
              "              disimular  masticación  pasapurés     criba  \n",
              "Determiner     0.000000     0.000000   0.000000  0.000000  \n",
              "Noun           0.000000     0.000002   0.000005  0.000003  \n",
              "Verb           0.000004     0.000000   0.000000  0.000000  \n",
              "Adposition     0.000000     0.000000   0.000000  0.000000  \n",
              "Adjective      0.000000     0.000000   0.000000  0.000000  \n",
              "Punctuation    0.000000     0.000000   0.000000  0.000000  \n",
              "Conjunction    0.000000     0.000000   0.000000  0.000000  \n",
              "Pronoun        0.000000     0.000000   0.000000  0.000000  \n",
              "Adverb         0.000000     0.000000   0.000000  0.000000  \n",
              "Number         0.000000     0.000000   0.000000  0.000000  \n",
              "Date           0.000000     0.000000   0.000000  0.000000  \n",
              "Interjection   0.000000     0.000000   0.000000  0.000000  \n",
              "\n",
              "[12 rows x 67416 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>la</th>\n",
              "      <th>es</th>\n",
              "      <th>una</th>\n",
              "      <th>institución</th>\n",
              "      <th>de</th>\n",
              "      <th>educación</th>\n",
              "      <th>superior</th>\n",
              "      <th>inspiración</th>\n",
              "      <th>cristiana</th>\n",
              "      <th>,</th>\n",
              "      <th>...</th>\n",
              "      <th>espiritu</th>\n",
              "      <th>desalineación</th>\n",
              "      <th>neandertales</th>\n",
              "      <th>cro-magnon</th>\n",
              "      <th>cromañón</th>\n",
              "      <th>prognatismo</th>\n",
              "      <th>disimular</th>\n",
              "      <th>masticación</th>\n",
              "      <th>pasapurés</th>\n",
              "      <th>criba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Determiner</th>\n",
              "      <td>0.250913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054342</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Noun</th>\n",
              "      <td>0.001173</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000426</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Verb</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.059271</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adposition</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.426120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adjective</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002114</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000537</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Punctuation</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conjunction</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pronoun</th>\n",
              "      <td>0.015037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adverb</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000567</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Interjection</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12 rows × 67416 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9594EmyyNlW"
      },
      "source": [
        "Se extrae la información de transición de cada fichero. Como en todos los ficheros los estados de inicio de transición y fin de transición son los mismos, se puede realizar una media de los valores para obtener la tabla de probabilidades de transición definitiva. Una vez creada, se guarda como xlsx."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3o0bb3T0_4L"
      },
      "source": [
        "PTrans_Total = HMM[0].PTrans()\n",
        "first_iter=1\n",
        "cnt_row=0\n",
        "for row in HMM:\n",
        "  if not first_iter:\n",
        "    PTrans_Total = row.PTrans() + PTrans_Total\n",
        " \n",
        "  first_iter=0\n",
        "  cnt_row+=1\n",
        "\n",
        "PTrans_Total = PTrans_Total/cnt_row\n",
        "PTrans_Total.to_excel('Desktop/docs/Total_Transmision.xlsx', sheet_name='prob_trans')\n",
        "del PTrans_Total\n",
        "del cnt_row\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0JEcFQVy0qE"
      },
      "source": [
        "Se repite el mismo procedimiento para las tablas de emisión. En este caso, los estados de cafa fichero serán los mismos, pero no los tokens. Por tanto, se deberá almacenar la frecuencia de aparición de éstos en una matriz auxiliar denominada *divider*, a partir de la que se podrá efectuar la media relativa a cada token en cada caso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqJea-ppZM7P"
      },
      "source": [
        "PObs_Total = HMM[0].PObs().copy()\n",
        "divider = dict()\n",
        "firstone=0\n",
        "\n",
        "for hmm in HMM:\n",
        "  if firstone:\n",
        "    for cols in hmm.PObs().columns.values:\n",
        "      try:\n",
        "          PObs_Total[cols] = PObs_Total[cols] + hmm.PObs()[cols]\n",
        "          try:\n",
        "            divider[cols] += 1 \n",
        "          except:\n",
        "            divider[cols] = 2\n",
        "      except:\n",
        "        PObs_Total[cols]= hmm.PObs()[cols]\n",
        "        try:\n",
        "            divider[cols] += 1        \n",
        "        except:\n",
        "            divider[cols] = 2\n",
        "  firstone=1\n",
        "\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzyfY0oszlAW"
      },
      "source": [
        "Se almacena la tabla de probabilidad de emisión como xlsx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4WileaJ-47B"
      },
      "source": [
        "PObs_Total\n",
        "del HMM\n",
        "del firstone"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnUNaQ72dUS_"
      },
      "source": [
        "PObs_Total.T.to_excel('Desktop/docs/Total_emision.xlsx', sheet_name='prob_emission')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8_VuXvl0a8T"
      },
      "source": [
        "Se calcula la mencionada media relativa a cada token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztMPRLUUSvkK"
      },
      "source": [
        "PObs_TotalDIV = pd.DataFrame()\n",
        "for cols in PObs_Total.columns.values:\n",
        "    try:\n",
        "        PObs_TotalDIV[cols] = PObs_Total[cols] / divider[cols]\n",
        "    except:\n",
        "        PObs_TotalDIV[cols] = PObs_Total[cols]     "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDGixj240fTz"
      },
      "source": [
        "Se obtiene y se guarda la tabla de emision definitiva creada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAdGouzcPDyG"
      },
      "source": [
        "PObs_TotalDIV.T.to_excel('Desktop/docs/Total_Emission.xlsx', sheet_name='prob_obs') "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt60sL4Vx3XC"
      },
      "source": [
        "np.save('Desktop/docs/total_divider', divider)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GwkYz_F0sCy"
      },
      "source": [
        "Se guarda el diccionario de lemas y el de lemas eliminados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH2fva6dom6s"
      },
      "source": [
        "np.save('Desktop/docs/LemmaDictionaries', DictLemmas)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaZwIaanoGLN"
      },
      "source": [
        "np.save('Desktop/docs/DiccionarioEliminar', RemovedLemmaDict)\n",
        "del PObs_TotalDIV\n",
        "del PObs_Total\n",
        "del divider"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23IcMxcU08yz"
      },
      "source": [
        "Por último, si se deseara, se podría filtrar el contenido del diccionario de lemas para asegurar que no aparezcan ciertas palabras del diccionario de lemas elimados. Sin embargo, esta aproximación no se contemplará para el proyecto, por este motivo, la celda en la que se guarda el diccionario filtrado aparece comentada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiIUrYx7oQsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebde85b-1732-44eb-8d8f-db04329739b4"
      },
      "source": [
        "len(RemovedLemmaDict)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1718284"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWttvZE1rrJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4914e5c-618f-42e3-c01b-d09161b883a0"
      },
      "source": [
        "len(DictLemmas)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "385599"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LkleUOXsJMs"
      },
      "source": [
        "for clave in RemovedLemmaDict.keys():\n",
        "    if clave in DictLemmas.keys():\n",
        "        del DictLemmas[clave]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phdGiFOwseZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07abea79-617b-490e-d030-b19474393c85"
      },
      "source": [
        "len(DictLemmas)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299878"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMxS9IgTstCd"
      },
      "source": [
        "#np.save('Desktop/docs/LemmaDictionariesDef', DictLemmas)"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}